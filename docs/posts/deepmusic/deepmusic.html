<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sophie Seiple">
<meta name="dcterms.date" content="2024-05-10">
<meta name="description" content="Using spotify data and neural networks to classify songs.">

<title>My Awesome CSCI 0451 Blog - Deep Music Genre Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deep Music Genre Classification</h1>
                  <div>
        <div class="description">
          Using spotify data and neural networks to classify songs.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Sophie Seiple </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 10, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>This blog post presents an approach to music genre classification using deep learning on a dataset of song information from Spotify. I trained three neural network models: one using only the song lyrics, one using only the engineered numeric features, and one combining both the lyrics and engineered features. The lyrics are preprocessed by filtering for common tokens and employing embedding layers, while the engineered features utilize fully-connected layers. The models’ genre classification performance is evaluated on a validation set and compared to a baseline rate. Additionally, the post explores visualizing the learned word embeddings to gain insights into the models. I created extra visualizations to investigate potential relationships between genres and engineered features like danceability, sadness, and audio characteristics over time.</p>
<p>First, I read in and examind the data.</p>
<div id="cell-3" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># read in data</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">artist_name</th>
<th data-quarto-table-cell-role="th">track_name</th>
<th data-quarto-table-cell-role="th">release_date</th>
<th data-quarto-table-cell-role="th">genre</th>
<th data-quarto-table-cell-role="th">lyrics</th>
<th data-quarto-table-cell-role="th">len</th>
<th data-quarto-table-cell-role="th">dating</th>
<th data-quarto-table-cell-role="th">violence</th>
<th data-quarto-table-cell-role="th">world/life</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">sadness</th>
<th data-quarto-table-cell-role="th">feelings</th>
<th data-quarto-table-cell-role="th">danceability</th>
<th data-quarto-table-cell-role="th">loudness</th>
<th data-quarto-table-cell-role="th">acousticness</th>
<th data-quarto-table-cell-role="th">instrumentalness</th>
<th data-quarto-table-cell-role="th">valence</th>
<th data-quarto-table-cell-role="th">energy</th>
<th data-quarto-table-cell-role="th">topic</th>
<th data-quarto-table-cell-role="th">age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>mukesh</td>
<td>mohabbat bhi jhoothi</td>
<td>1950</td>
<td>pop</td>
<td>hold time feel break feel untrue convince spea...</td>
<td>95</td>
<td>0.000598</td>
<td>0.063746</td>
<td>0.000598</td>
<td>...</td>
<td>0.380299</td>
<td>0.117175</td>
<td>0.357739</td>
<td>0.454119</td>
<td>0.997992</td>
<td>0.901822</td>
<td>0.339448</td>
<td>0.137110</td>
<td>sadness</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>frankie laine</td>
<td>i believe</td>
<td>1950</td>
<td>pop</td>
<td>believe drop rain fall grow believe darkest ni...</td>
<td>51</td>
<td>0.035537</td>
<td>0.096777</td>
<td>0.443435</td>
<td>...</td>
<td>0.001284</td>
<td>0.001284</td>
<td>0.331745</td>
<td>0.647540</td>
<td>0.954819</td>
<td>0.000002</td>
<td>0.325021</td>
<td>0.263240</td>
<td>world/life</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>6</td>
<td>johnnie ray</td>
<td>cry</td>
<td>1950</td>
<td>pop</td>
<td>sweetheart send letter goodbye secret feel bet...</td>
<td>24</td>
<td>0.002770</td>
<td>0.002770</td>
<td>0.002770</td>
<td>...</td>
<td>0.002770</td>
<td>0.225422</td>
<td>0.456298</td>
<td>0.585288</td>
<td>0.840361</td>
<td>0.000000</td>
<td>0.351814</td>
<td>0.139112</td>
<td>music</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>10</td>
<td>pérez prado</td>
<td>patricia</td>
<td>1950</td>
<td>pop</td>
<td>kiss lips want stroll charm mambo chacha merin...</td>
<td>54</td>
<td>0.048249</td>
<td>0.001548</td>
<td>0.001548</td>
<td>...</td>
<td>0.225889</td>
<td>0.001548</td>
<td>0.686992</td>
<td>0.744404</td>
<td>0.083935</td>
<td>0.199393</td>
<td>0.775350</td>
<td>0.743736</td>
<td>romantic</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>12</td>
<td>giorgos papadopoulos</td>
<td>apopse eida oneiro</td>
<td>1950</td>
<td>pop</td>
<td>till darling till matter know till dream live ...</td>
<td>48</td>
<td>0.001350</td>
<td>0.001350</td>
<td>0.417772</td>
<td>...</td>
<td>0.068800</td>
<td>0.001350</td>
<td>0.291671</td>
<td>0.646489</td>
<td>0.975904</td>
<td>0.000246</td>
<td>0.597073</td>
<td>0.394375</td>
<td>romantic</td>
<td>1.0</td>
</tr>
</tbody>
</table>

<p>5 rows × 31 columns</p>
</div>
</div>
</div>
</div>
<div id="cell-5" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>, category <span class="op">=</span> <span class="pp">UserWarning</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next I wanted to see what our baseline accuracy was, i.e.&nbsp;the accuracy we get from guessting the same label everytime.</p>
<div id="cell-7" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">"genre"</span>).size() <span class="op">/</span> <span class="bu">len</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>genre
blues      0.162273
country    0.191915
hip hop    0.031862
jazz       0.135521
pop        0.248202
reggae     0.088045
rock       0.142182
dtype: float64</code></pre>
</div>
</div>
<p>We want our model accuracy to be &gt;24%, since this would be equivalent to predicting pop every single time.</p>
<p>Next, I encoded the genre labels so that we could feed them into our model.</p>
<div id="cell-10" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>genres <span class="op">=</span> {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"blues"</span>   : <span class="dv">0</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"country"</span> : <span class="dv">1</span>, </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"hip hop"</span> : <span class="dv">2</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"jazz"</span>    : <span class="dv">3</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pop"</span>     : <span class="dv">4</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"reggae"</span>  : <span class="dv">5</span>, </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"rock"</span>    : <span class="dv">6</span>,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">"genre"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x <span class="kw">in</span> genres.keys())]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"genre"</span>] <span class="op">=</span> df[<span class="st">"genre"</span>].<span class="bu">apply</span>(genres.get)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then I implemented a slightly modified version of the data retrieving function from the lecture notes.</p>
<div id="cell-12" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DataFromDF(Dataset):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, df):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> df </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return lyrics, genre, and engineered features via their indices</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.df.iloc[index, <span class="dv">5</span>], <span class="va">self</span>.df.iloc[index, <span class="dv">4</span>], <span class="va">self</span>.df.iloc[index, <span class="dv">6</span>:<span class="dv">28</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I then split the data into training and testing data, and retrieved the columns we wanted to focus on using our function for both training and testing.</p>
<div id="cell-14" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df_train, df_val <span class="op">=</span> train_test_split(df,shuffle <span class="op">=</span> <span class="va">True</span>, test_size <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># retrieve data</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> DataFromDF(df_train)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>val_data   <span class="op">=</span> DataFromDF(df_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, I built a tokenizer so that we could use the lyrics features of the songs in our model. This code is also adapted from the lecture notes.</p>
<div id="cell-16" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchtext.data.utils <span class="im">import</span> get_tokenizer</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchtext.vocab <span class="im">import</span> build_vocab_from_iterator</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> get_tokenizer(<span class="st">'basic_english'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># function to generate tokens from a data iterator</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> yield_tokens(data_iter):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text, features, lab <span class="kw">in</span> data_iter:</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> tokenizer(text)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># build vocabulary from tokens generated by the yield_tokens function</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> build_vocab_from_iterator(yield_tokens(train_data), specials<span class="op">=</span>[<span class="st">"&lt;unk&gt;"</span>], min_freq <span class="op">=</span> <span class="dv">50</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>vocab.set_default_index(vocab[<span class="st">"&lt;unk&gt;"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>max_len <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>num_tokens <span class="op">=</span> <span class="bu">len</span>(vocab.get_itos())</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># function to process text data into token indices</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># also taken from the lecture notes on text processing</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_pipeline(x):</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> vocab(tokenizer(x))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> torch.zeros(max_len, dtype<span class="op">=</span>torch.int64) <span class="op">+</span> num_tokens</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(tokens) <span class="op">&gt;</span> max_len:</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> tokens[<span class="dv">0</span>:max_len]</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    y[<span class="dv">0</span>:<span class="bu">len</span>(tokens)] <span class="op">=</span> torch.tensor(tokens,dtype<span class="op">=</span>torch.int64)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># function to process label data</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>label_pipeline <span class="op">=</span> <span class="kw">lambda</span> x: <span class="bu">int</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is an example of using this text pipeline on a few words of a song from our dataset:</p>
<div id="cell-20" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>text_pipeline(<span class="st">"chaos come clarity"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([2267,    4,    0, 2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904,
        2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904, 2904,
        2904, 2904, 2904, 2904, 2904, 2904])</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># function to collate a batch of data samples</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># also adapted from the lecture notes on text processing</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collate_batch(batch):</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>     <span class="co"># initialize empty lists to store labels, processed text, and features</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    label_list, text_list, features_list <span class="op">=</span> [], [], []</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iterate over each sample in the batch</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (text, label, features) <span class="kw">in</span> batch:</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># process label and add to the label list</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        label_list.append(label_pipeline(label))</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># process text and add to the text list</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        processed_text <span class="op">=</span> text_pipeline(text)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        text_list.append(processed_text)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convert features to torch tensor and add to the features list</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        features_list.append(torch.tensor(features))  <span class="co"># Convert features to torch.int64</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    label_list <span class="op">=</span> torch.tensor(label_list, dtype<span class="op">=</span>torch.int64)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    text_list <span class="op">=</span> torch.stack(text_list)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    features_list <span class="op">=</span> torch.stack(features_list)  <span class="co"># Stack features tensors</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the processed batch: text tensor, label tensor, and features tensor</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text_list, label_list, features_list </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next I set up my dataloaders from PyTorch’s DataLoader class.</p>
<div id="cell-23" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoader for the training dataset</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, collate_fn<span class="op">=</span>collate_batch)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoader for the validation dataset</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(val_data, batch_size<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, collate_fn<span class="op">=</span>collate_batch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first network I defined was the network that uses only the lyric data, this was my TextNet clas. This code was also adapted from our lecture notes on text processing.</p>
<div id="cell-25" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TextNet(nn.Module):</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># constructor method, initializing the layers</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size, embedding_dim, num_class):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the embedding layer</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(vocab_size <span class="op">+</span> <span class="dv">1</span>, embedding_dim)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the dropout layer</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout (p<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the fully connected layer</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(embedding_dim, num_class)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># method defining how data flows through the network</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, text):</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># pass the input text through the embedding layer</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> <span class="va">self</span>.embedding(text)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># apply dropout to the embedded text</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> <span class="va">self</span>.dropout(text)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the mean across the sequence dimension</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> text.mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># pass the result through the fully connected layer</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> <span class="va">self</span>.fc(text)   </span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> text</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next I defined the neural network that we’ll use for our engineered features only model, this was my FeaturesNet class.</p>
<div id="cell-27" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FeaturesNet(nn.Module):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># constructor method, initializing the layers</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, size, num_class):</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define the feature model as a sequence of layers</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.featmodel <span class="op">=</span> nn.Sequential(nn.Linear(size, <span class="dv">128</span>), nn.ReLU(), nn.Dropout(<span class="fl">0.2</span>), nn.Linear(<span class="dv">128</span>, <span class="dv">64</span>), nn.ReLU(), nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">64</span>, <span class="dv">32</span>), nn.ReLU(), nn.Dropout(<span class="fl">0.2</span>), nn.Linear(<span class="dv">32</span>, <span class="dv">16</span>), nn.ReLU(), nn.Dropout(<span class="fl">0.2</span>), nn.Linear(<span class="dv">16</span>, num_class),</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># method defining how data flows through the network </span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, feats):</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convert feats to float type</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        feats <span class="op">=</span> feats.<span class="bu">float</span>()</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># flatten the features tensor</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        feats <span class="op">=</span> torch.flatten(feats, <span class="dv">1</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># pass the flattened features through the feature model</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        feats <span class="op">=</span> <span class="va">self</span>.featmodel(feats)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> feats</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Lastly, I defined a network that is able to use both lyrics and features, this was my CombinedNet class.</p>
<div id="cell-29" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CombinedNet(nn.Module):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># constructor method, initializing the layers</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size, embedding_dim, num_features, num_class):</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># same process as in the original lyric model</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(vocab_size<span class="op">+</span><span class="dv">1</span>, embedding_dim)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout (p<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_fc <span class="op">=</span> nn.Linear(embedding_dim, <span class="dv">128</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># similar model to the original feature only model</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.engineered_model <span class="op">=</span> nn.Sequential(nn.Linear(num_features, <span class="dv">256</span>), nn.ReLU(), nn.Dropout(<span class="fl">0.2</span>), nn.Linear(<span class="dv">256</span>, <span class="dv">128</span>))</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># fully connected layer for combining text and engineered features</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.combine_fc <span class="op">=</span> nn.Linear(<span class="dv">3968</span>, <span class="dv">64</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># output fully connected layer</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_fc <span class="op">=</span> nn.Linear(<span class="dv">64</span>, num_class)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># softmax activation for classification output</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.softmax <span class="op">=</span> nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># method defining how data flows through the network</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, text, features):</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># similar to lyrics only model</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        text_em <span class="op">=</span> <span class="va">self</span>.embedding(text)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        text_dr <span class="op">=</span> <span class="va">self</span>.dropout(text_em)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>        text_processed <span class="op">=</span> <span class="va">self</span>.text_fc(text_dr)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>        text_processed <span class="op">=</span> torch.flatten(text_processed, <span class="dv">1</span>)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># similar to features only model</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> features.<span class="bu">float</span>()</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        engineered_processed <span class="op">=</span> <span class="va">self</span>.engineered_model(features)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># concatenate text and engineered features</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>        cat <span class="op">=</span> torch.cat((text_processed, engineered_processed), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># process combined features through the output fully connected layer</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>        cat <span class="op">=</span> <span class="va">self</span>.combine_fc(cat)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.output_fc(cat)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.softmax(output)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then I defined my training and evaluation methods for all three models, again adapted from our lecture on text processing. I use one training and evaluation method for all three of my neural networks by taking in a state parameter that tells us what kind of information needs to be passed to the model.</p>
<div id="cell-31" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, dataloader, optimizer, loss_fn, epoch, state<span class="op">=</span><span class="st">'both'</span>):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    epoch_start_time <span class="op">=</span> time.time()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># keep track of some counts for measuring accuracy</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    total_acc, total_count <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    log_interval <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iterate over batches in the dataloader</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (text, label, features) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zero gradients</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># depending on the given state (what the model should be allowed to use)</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> state <span class="op">==</span> <span class="st">'both'</span>:</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>            predicted_label <span class="op">=</span> model(text, features)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> state <span class="op">==</span> <span class="st">'lyrics'</span>:</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>            predicted_label <span class="op">=</span> model(text)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> state <span class="op">==</span> <span class="st">'features'</span>:</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>            predicted_label <span class="op">=</span> model(features)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># evaluate loss on prediction</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(predicted_label, label)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute gradient</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># take an optimization step</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># for printing accuracy</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        total_acc   <span class="op">+=</span> (predicted_label.argmax(<span class="dv">1</span>) <span class="op">==</span> label).<span class="bu">sum</span>().item()</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        total_count <span class="op">+=</span> label.size(<span class="dv">0</span>)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'| epoch </span><span class="sc">{</span>epoch<span class="sc">:3d}</span><span class="ss"> | train accuracy </span><span class="sc">{</span>total_acc<span class="op">/</span>total_count<span class="sc">:8.3f}</span><span class="ss"> | time: </span><span class="sc">{</span>time<span class="sc">.</span>time() <span class="op">-</span> epoch_start_time<span class="sc">:5.2f}</span><span class="ss">s'</span>)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate(model, dataloader, state<span class="op">=</span><span class="st">'both'</span>):</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>    total_acc, total_count <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iterate over batches in the dataloader</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx, (text, label, features) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># depending on the given state (what the model should be allowed to use) </span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> state <span class="op">==</span> <span class="st">'both'</span>:</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>                predicted_label <span class="op">=</span> model(text, features)</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> state <span class="op">==</span> <span class="st">'lyrics'</span>:</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>                predicted_label <span class="op">=</span> model(text)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> state <span class="op">==</span> <span class="st">'features'</span>:</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>                predicted_label <span class="op">=</span> model(features)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>            total_acc <span class="op">+=</span> (predicted_label.argmax(<span class="dv">1</span>) <span class="op">==</span> label).<span class="bu">sum</span>().item()</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>            total_count <span class="op">+=</span> label.size(<span class="dv">0</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_acc<span class="op">/</span>total_count</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, I defined my outer loop, which makes it easy to create and train any of the three models with a single function.</p>
<div id="cell-33" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> outer_loop(train_loader, val_loader, state<span class="op">=</span><span class="st">'both'</span>):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># define parameters according to what we know of the data</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    vocab_size <span class="op">=</span> <span class="bu">len</span>(vocab)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    embedding_dim <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    num_features <span class="op">=</span> <span class="dv">22</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>     <span class="co"># train a model based on the specified state</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> state <span class="op">==</span> <span class="st">'both'</span>:</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use combined class</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> CombinedNet(vocab_size, embedding_dim, num_features, num_classes).to(device)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.000001</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># training loop</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        EPOCHS <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, EPOCHS <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>            train(model, train_loader, optimizer, loss_fn, epoch, <span class="st">'both'</span>)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># evaluate and print accuracy on validation set</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: '</span>, evaluate(model, val_loader, state<span class="op">=</span><span class="st">'both'</span>))</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> state <span class="op">==</span> <span class="st">'lyrics'</span>:</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use lyrics class</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> TextNet(vocab_size, embedding_dim, num_classes).to(device)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># training loop</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        EPOCHS <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, EPOCHS <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>            train(model, train_loader, optimizer, loss_fn, epoch, <span class="st">'lyrics'</span>)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># evaluate and print accuracy on validation set</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: '</span>, evaluate(model, val_loader, state<span class="op">=</span><span class="st">'lyrics'</span>))</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> state <span class="op">==</span> <span class="st">'features'</span>:</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use features class</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> FeaturesNet(num_features, num_classes).to(device)</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># training loop</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        EPOCHS <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, EPOCHS <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>            train(model, train_loader, optimizer, loss_fn, epoch, <span class="st">'features'</span>)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># evaluate and print accuracy on validation set</span></span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Accuracy: '</span>, evaluate(model, val_loader, state<span class="op">=</span><span class="st">'features'</span>))</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With all of these function defined, I can move on to training my models and exploring their accuracies.</p>
</section>
<section id="lyrics-only" class="level2">
<h2 class="anchored" data-anchor-id="lyrics-only">Lyrics Only</h2>
<p>The first model I looked at was the model that only considered the input of lyrics.</p>
<div id="cell-37" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>lyric_model <span class="op">=</span> outer_loop(train_loader, val_loader, <span class="st">'lyrics'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/b9/j0x1vdx94513n863t09wz2d80000gn/T/ipykernel_41870/1069164222.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  features_list.append(torch.tensor(features))  # Convert features to torch.int64</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>| epoch   1 | train accuracy    0.228 | time:  4.69s
| epoch   2 | train accuracy    0.248 | time:  4.61s
| epoch   3 | train accuracy    0.255 | time:  4.52s
| epoch   4 | train accuracy    0.266 | time:  4.57s
| epoch   5 | train accuracy    0.275 | time:  4.46s
| epoch   6 | train accuracy    0.285 | time:  4.43s
| epoch   7 | train accuracy    0.297 | time:  4.69s
| epoch   8 | train accuracy    0.303 | time:  4.69s
| epoch   9 | train accuracy    0.312 | time:  4.53s
| epoch  10 | train accuracy    0.317 | time:  4.54s
| epoch  11 | train accuracy    0.321 | time:  4.65s
| epoch  12 | train accuracy    0.326 | time:  4.60s
| epoch  13 | train accuracy    0.333 | time:  4.62s
| epoch  14 | train accuracy    0.340 | time:  4.60s
| epoch  15 | train accuracy    0.344 | time:  4.65s
| epoch  16 | train accuracy    0.350 | time:  4.66s
| epoch  17 | train accuracy    0.350 | time:  4.67s
| epoch  18 | train accuracy    0.355 | time:  4.71s
| epoch  19 | train accuracy    0.361 | time:  4.77s
| epoch  20 | train accuracy    0.359 | time:  4.72s
| epoch  21 | train accuracy    0.367 | time:  4.70s
| epoch  22 | train accuracy    0.369 | time:  4.70s
| epoch  23 | train accuracy    0.370 | time:  4.80s
| epoch  24 | train accuracy    0.374 | time:  4.93s
| epoch  25 | train accuracy    0.379 | time:  4.78s
| epoch  26 | train accuracy    0.377 | time:  4.93s
| epoch  27 | train accuracy    0.382 | time:  4.87s
| epoch  28 | train accuracy    0.383 | time:  4.80s
| epoch  29 | train accuracy    0.387 | time:  4.79s
| epoch  30 | train accuracy    0.385 | time:  4.78s
| epoch  31 | train accuracy    0.388 | time:  4.79s
| epoch  32 | train accuracy    0.392 | time:  4.82s
| epoch  33 | train accuracy    0.393 | time:  4.79s
| epoch  34 | train accuracy    0.391 | time:  4.79s
| epoch  35 | train accuracy    0.397 | time:  4.80s
| epoch  36 | train accuracy    0.392 | time:  4.79s
| epoch  37 | train accuracy    0.397 | time:  4.81s
| epoch  38 | train accuracy    0.397 | time:  4.86s
| epoch  39 | train accuracy    0.400 | time:  4.81s
| epoch  40 | train accuracy    0.398 | time:  4.83s
| epoch  41 | train accuracy    0.403 | time:  4.82s
| epoch  42 | train accuracy    0.401 | time:  4.84s
| epoch  43 | train accuracy    0.401 | time:  4.92s
| epoch  44 | train accuracy    0.407 | time:  4.87s
| epoch  45 | train accuracy    0.408 | time:  4.88s
| epoch  46 | train accuracy    0.406 | time:  4.87s
| epoch  47 | train accuracy    0.407 | time:  4.85s
| epoch  48 | train accuracy    0.406 | time:  4.88s
| epoch  49 | train accuracy    0.410 | time:  4.86s
| epoch  50 | train accuracy    0.410 | time:  4.88s
Accuracy:  0.32933920704845815</code></pre>
</div>
</div>
<p>Our resulting neural network is not incredibly accurate, only classifying songs correctly around 32.47% of the time. However, this is still 8% better than our baseline measure of 24%, so the model is doing better than it would be guessing the same label every time.</p>
</section>
<section id="features-only" class="level2">
<h2 class="anchored" data-anchor-id="features-only">Features Only</h2>
<p>Next, I looked at the model that only considered features.</p>
<div id="cell-41" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>features_model <span class="op">=</span> outer_loop(train_loader, val_loader, <span class="st">'features'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/b9/j0x1vdx94513n863t09wz2d80000gn/T/ipykernel_41870/1069164222.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  features_list.append(torch.tensor(features))  # Convert features to torch.int64</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>| epoch   1 | train accuracy    0.243 | time:  5.39s
| epoch   2 | train accuracy    0.249 | time:  5.38s
| epoch   3 | train accuracy    0.259 | time:  5.38s
| epoch   4 | train accuracy    0.273 | time:  6.85s
| epoch   5 | train accuracy    0.286 | time:  5.72s
| epoch   6 | train accuracy    0.287 | time:  5.47s
| epoch   7 | train accuracy    0.299 | time:  5.66s
| epoch   8 | train accuracy    0.301 | time:  5.49s
| epoch   9 | train accuracy    0.302 | time:  5.57s
| epoch  10 | train accuracy    0.302 | time:  5.70s
| epoch  11 | train accuracy    0.308 | time:  5.64s
| epoch  12 | train accuracy    0.310 | time:  5.47s
| epoch  13 | train accuracy    0.310 | time:  5.43s
| epoch  14 | train accuracy    0.311 | time:  5.41s
| epoch  15 | train accuracy    0.309 | time:  5.41s
| epoch  16 | train accuracy    0.313 | time:  5.47s
| epoch  17 | train accuracy    0.313 | time:  5.43s
| epoch  18 | train accuracy    0.308 | time:  5.41s
| epoch  19 | train accuracy    0.314 | time:  5.42s
| epoch  20 | train accuracy    0.315 | time:  5.43s
| epoch  21 | train accuracy    0.316 | time:  5.43s
| epoch  22 | train accuracy    0.313 | time:  5.44s
| epoch  23 | train accuracy    0.316 | time:  5.40s
| epoch  24 | train accuracy    0.314 | time:  5.49s
| epoch  25 | train accuracy    0.314 | time:  5.51s
| epoch  26 | train accuracy    0.319 | time:  5.48s
| epoch  27 | train accuracy    0.315 | time:  5.65s
| epoch  28 | train accuracy    0.315 | time:  5.46s
| epoch  29 | train accuracy    0.319 | time:  5.53s
| epoch  30 | train accuracy    0.323 | time:  5.76s
| epoch  31 | train accuracy    0.317 | time:  5.61s
| epoch  32 | train accuracy    0.319 | time:  5.56s
| epoch  33 | train accuracy    0.319 | time:  5.58s
| epoch  34 | train accuracy    0.318 | time:  5.63s
| epoch  35 | train accuracy    0.320 | time:  5.58s
| epoch  36 | train accuracy    0.309 | time:  5.46s
| epoch  37 | train accuracy    0.318 | time:  5.49s
| epoch  38 | train accuracy    0.319 | time:  5.52s
| epoch  39 | train accuracy    0.319 | time:  5.57s
| epoch  40 | train accuracy    0.318 | time:  5.45s
| epoch  41 | train accuracy    0.323 | time:  5.51s
| epoch  42 | train accuracy    0.317 | time:  5.51s
| epoch  43 | train accuracy    0.322 | time:  5.64s
| epoch  44 | train accuracy    0.323 | time:  5.49s
| epoch  45 | train accuracy    0.322 | time:  5.49s
| epoch  46 | train accuracy    0.321 | time:  5.51s
| epoch  47 | train accuracy    0.326 | time:  5.69s
| epoch  48 | train accuracy    0.326 | time:  5.56s
| epoch  49 | train accuracy    0.323 | time:  5.96s
| epoch  50 | train accuracy    0.322 | time:  5.74s
Accuracy:  0.3309251101321586</code></pre>
</div>
</div>
<p>Again, our accuracy is relatively low, but we are able to do better than the baseline accuracy of 24%, so our model is learning.</p>
</section>
<section id="using-both" class="level2">
<h2 class="anchored" data-anchor-id="using-both">Using Both</h2>
<p>Lastly, I created and trained the model that uses both features and lyrics in classification.</p>
<div id="cell-45" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>outer_loop(train_loader, val_loader, <span class="st">'both'</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/b9/j0x1vdx94513n863t09wz2d80000gn/T/ipykernel_42158/1069164222.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  features_list.append(torch.tensor(features))  # Convert features to torch.int64</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>| epoch   1 | train accuracy    0.240 | time:  6.47s
| epoch   2 | train accuracy    0.250 | time:  6.20s
| epoch   3 | train accuracy    0.251 | time:  6.38s
| epoch   4 | train accuracy    0.254 | time:  6.31s
| epoch   5 | train accuracy    0.256 | time:  6.42s
| epoch   6 | train accuracy    0.257 | time:  6.18s
| epoch   7 | train accuracy    0.262 | time:  6.25s
| epoch   8 | train accuracy    0.260 | time:  6.28s
| epoch   9 | train accuracy    0.262 | time:  6.78s
| epoch  10 | train accuracy    0.262 | time:  6.60s
| epoch  11 | train accuracy    0.264 | time:  6.64s
| epoch  12 | train accuracy    0.263 | time:  6.86s
| epoch  13 | train accuracy    0.264 | time:  6.77s
| epoch  14 | train accuracy    0.265 | time:  7.41s
| epoch  15 | train accuracy    0.268 | time:  7.16s
| epoch  16 | train accuracy    0.266 | time:  6.85s
| epoch  17 | train accuracy    0.265 | time:  7.09s
| epoch  18 | train accuracy    0.265 | time:  7.03s
| epoch  19 | train accuracy    0.266 | time:  7.46s
| epoch  20 | train accuracy    0.267 | time:  6.72s
| epoch  21 | train accuracy    0.268 | time:  7.14s
| epoch  22 | train accuracy    0.268 | time:  7.05s
| epoch  23 | train accuracy    0.267 | time:  6.79s
| epoch  24 | train accuracy    0.270 | time:  7.05s
| epoch  25 | train accuracy    0.268 | time:  7.71s
| epoch  26 | train accuracy    0.270 | time:  7.52s
| epoch  27 | train accuracy    0.270 | time:  6.93s
| epoch  28 | train accuracy    0.268 | time:  6.88s
| epoch  29 | train accuracy    0.270 | time:  7.00s
| epoch  30 | train accuracy    0.267 | time:  7.05s
| epoch  31 | train accuracy    0.270 | time:  7.13s
| epoch  32 | train accuracy    0.268 | time:  7.06s
| epoch  33 | train accuracy    0.268 | time:  6.94s
| epoch  34 | train accuracy    0.269 | time:  7.28s
| epoch  35 | train accuracy    0.268 | time:  7.11s
| epoch  36 | train accuracy    0.270 | time:  7.11s
| epoch  37 | train accuracy    0.268 | time:  7.06s
| epoch  38 | train accuracy    0.268 | time:  7.20s
| epoch  39 | train accuracy    0.271 | time:  6.94s
| epoch  40 | train accuracy    0.270 | time:  7.25s
| epoch  41 | train accuracy    0.269 | time:  8.26s
| epoch  42 | train accuracy    0.270 | time:  6.97s
| epoch  43 | train accuracy    0.271 | time:  7.09s
| epoch  44 | train accuracy    0.271 | time:  6.92s
| epoch  45 | train accuracy    0.273 | time:  7.64s
| epoch  46 | train accuracy    0.272 | time:  8.15s
| epoch  47 | train accuracy    0.272 | time:  9.83s
| epoch  48 | train accuracy    0.272 | time:  8.05s
| epoch  49 | train accuracy    0.272 | time:  8.11s
| epoch  50 | train accuracy    0.275 | time:  8.18s
Accuracy:  0.25744493392070483</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>CombinedNet(
  (embedding): Embedding(2905, 3)
  (dropout): Dropout(p=0.2, inplace=False)
  (text_fc): Linear(in_features=3, out_features=128, bias=True)
  (engineered_model): Sequential(
    (0): Linear(in_features=22, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=256, out_features=128, bias=True)
  )
  (combine_fc): Linear(in_features=3968, out_features=64, bias=True)
  (output_fc): Linear(in_features=64, out_features=7, bias=True)
  (softmax): Softmax(dim=1)
)</code></pre>
</div>
</div>
<p>Interestingly, my combined model did worse than both of the seperate models, but still 1% better than our baseline accuracy.</p>
</section>
<section id="examining-word-embedding" class="level2">
<h2 class="anchored" data-anchor-id="examining-word-embedding">Examining Word Embedding</h2>
<p>Next, I created a few visualizations to explore the word embedding that my lyrics network generated.</p>
<div id="cell-49" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the word embeddings from the lyric_model and convert to NumPy array</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>emmat <span class="op">=</span> lyric_model.embedding.cpu().weight.data.numpy()</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components for 2D visualization</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># perform PCA on the word embeddings</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> pca.fit_transform(emmat)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># get the tokens (words) from the vocabulary</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> vocab.get_itos()</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>tokens.append(<span class="st">" "</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co"># create a DataFrame to store the word embeddings and their PCA-reduced dimensions</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>embed_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word'</span> : tokens,</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'w0'</span> : weights[:,<span class="dv">0</span>],</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'w1'</span> : weights[:,<span class="dv">1</span>]</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>embed_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">word</th>
<th data-quarto-table-cell-role="th">w0</th>
<th data-quarto-table-cell-role="th">w1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>&lt;unk&gt;</td>
<td>0.472313</td>
<td>-0.003740</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>know</td>
<td>0.069357</td>
<td>-0.285091</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>like</td>
<td>0.092207</td>
<td>-0.414570</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>time</td>
<td>-0.125206</td>
<td>-0.341289</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>come</td>
<td>0.067297</td>
<td>-0.144520</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>This is a dataframe representing our embedding results, with each word and its related position. I then used this dataframe to visualize any patterns in our embedding.</p>
<div id="cell-51" class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(embed_df[<span class="st">'w0'</span>], embed_df[<span class="st">'w1'</span>], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'First Principal Component (w0)'</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Second Principal Component (w1)'</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Word Embeddings Visualization using PCA'</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepmusic_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>No patterns were immediately clear in this graph, so I moved on to selecting a few specific words and examining their relationships to each other. The first group I visualized was words that I recognized as nicknames, as I wanted to see if they were all close together, or if some nicknames were closer to each other than others.</p>
<div id="cell-53" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># nicknames for people that appear in songs</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>group1 <span class="op">=</span> [<span class="st">'baby'</span>, <span class="st">'girl'</span>, <span class="st">'love'</span>, <span class="st">'sweet'</span>, <span class="st">'woman'</span>, <span class="st">'darling'</span>, <span class="st">'mama'</span>, <span class="st">'beautiful'</span>, <span class="st">'babe'</span>, <span class="st">'daddy'</span>, <span class="st">'queen'</span>, <span class="st">'hoe'</span>, <span class="st">'darlin'</span>, <span class="st">'momma'</span>, <span class="st">'beauty'</span>, <span class="st">'sister'</span>, <span class="st">'gyal'</span>, <span class="st">'shawty'</span>, </span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>          <span class="st">'dawg'</span>, <span class="st">'ting'</span>, <span class="st">'gangsta'</span>, <span class="st">'baddest'</span>, <span class="st">'princess'</span>, <span class="st">'twin'</span>, <span class="st">'man'</span>, <span class="st">'killa'</span>]</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>offset <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># plot subset of nicknames</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>group1_df <span class="op">=</span> embed_df[embed_df[<span class="st">'word'</span>].isin(group1)]</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(group1_df[<span class="st">'w0'</span>], group1_df[<span class="st">'w1'</span>], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># add word to plot</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> group1_df.iterrows():</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    plt.annotate(row[<span class="st">'word'</span>], (row[<span class="st">'w0'</span>] <span class="op">+</span> offset, row[<span class="st">'w1'</span>] <span class="op">+</span> offset))  <span class="co"># Add offset to coordinates</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'First Principal Component (w0)'</span>)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Second Principal Component (w1)'</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Nickname Word Embeddings'</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepmusic_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>All of the nicknames seem somewhat close together, which makes sense considering they all have related meanings. There are a few outliers away from the majority of nicknames, but I didn’t immeadiately see a shared characeristic between them that made them outliers.</p>
<p>Next I plotted words I associated with country music against words I associated with pop music.</p>
<div id="cell-56" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># words I think appear in country songs</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>country <span class="op">=</span> [<span class="st">'truck'</span>, <span class="st">'muddy'</span>, <span class="st">'boot'</span>, <span class="st">'rifle'</span>, <span class="st">'hunt'</span>, <span class="st">'fish'</span>, <span class="st">'man'</span>, <span class="st">'america'</span>, <span class="st">'wheel'</span>, <span class="st">'kentucky'</span>, <span class="st">'guitars'</span>, <span class="st">'whiskey'</span>, <span class="st">'chicken'</span>, <span class="st">'cowboy'</span>]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># words I think appear in pop songs</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>pop <span class="op">=</span> [<span class="st">'girl'</span>, <span class="st">'woman'</span>, <span class="st">'tonight'</span>, <span class="st">'baby'</span>, <span class="st">'yeah'</span>, <span class="st">'swag'</span>, <span class="st">'music'</span>, <span class="st">'party'</span>, <span class="st">'everybody'</span>, <span class="st">'young'</span>, <span class="st">'summer'</span>, <span class="st">'ohoh'</span>, <span class="st">'crew'</span>, <span class="st">'dance'</span>]</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co"># offset for graph labels</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>offset <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># create plottable df for the two word groups</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>country_df <span class="op">=</span> embed_df[embed_df[<span class="st">'word'</span>].isin(country)]</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>pop_df <span class="op">=</span> embed_df[embed_df[<span class="st">'word'</span>].isin(pop)]</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(country_df[<span class="st">'w0'</span>], country_df[<span class="st">'w1'</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> country_df.iterrows():</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    plt.annotate(row[<span class="st">'word'</span>], (row[<span class="st">'w0'</span>] <span class="op">+</span> offset, row[<span class="st">'w1'</span>] <span class="op">+</span> offset), color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(pop_df[<span class="st">'w0'</span>], pop_df[<span class="st">'w1'</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> pop_df.iterrows():</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>    plt.annotate(row[<span class="st">'word'</span>], (row[<span class="st">'w0'</span>] <span class="op">+</span> offset, row[<span class="st">'w1'</span>] <span class="op">+</span> offset), color<span class="op">=</span><span class="st">'red'</span>) </span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'First Principal Component (w0)'</span>)</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Second Principal Component (w1)'</span>)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Word Embeddings Visualization for Country and Pop Groups'</span>)</span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'Country'</span>, <span class="st">'Pop'</span>])</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepmusic_files/figure-html/cell-26-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Interestingly, the words I associate with pop music are all pretty close together, which would indicate that they are related in terms of guessing the genre, but the words I would associate with country music are much more spread out. The close embedding between the words ‘america’ and ‘woman’ was also quite surprising.</p>
</section>
<section id="optional-graphs" class="level2">
<h2 class="anchored" data-anchor-id="optional-graphs">Optional Graphs</h2>
<section id="has-pop-music-gotten-more-danceable-over-time-in-this-sample-according-to-spotifys-definition-of-danceability" class="level4">
<h4 class="anchored" data-anchor-id="has-pop-music-gotten-more-danceable-over-time-in-this-sample-according-to-spotifys-definition-of-danceability">1. Has pop music gotten more danceable over time in this sample, according to Spotify’s definition of danceability?</h4>
<div id="cell-60" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># finding average danceability per release year</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>average_danceability_per_year <span class="op">=</span> df.groupby(<span class="st">'release_date'</span>)[<span class="st">'danceability'</span>].mean()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>plt.plot(average_danceability_per_year.index, average_danceability_per_year.values, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Release Year'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Average Danceability'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Average Danceability per Year'</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepmusic_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This graph shows that over time songs have become more danceable according to spotify’s definition.</p>
</section>
<section id="does-blues-music-tend-to-have-more-sadness-than-other-genres-does-pop-or-rock-have-more-energy" class="level4">
<h4 class="anchored" data-anchor-id="does-blues-music-tend-to-have-more-sadness-than-other-genres-does-pop-or-rock-have-more-energy">2. Does blues music tend to have more sadness than other genres? Does pop or rock have more energy?</h4>
<div id="cell-63" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">'genre'</span>, <span class="st">'dating'</span>, <span class="st">'violence'</span>, <span class="st">'world/life'</span>, <span class="st">'night/time'</span>,<span class="st">'shake the audience'</span>,<span class="st">'family/gospel'</span>, <span class="st">'romantic'</span>, <span class="st">'communication'</span>,<span class="st">'obscene'</span>, <span class="st">'music'</span>, <span class="st">'movement/places'</span>, <span class="st">'light/visual perceptions'</span>,<span class="st">'family/spiritual'</span>, <span class="st">'like/girls'</span>, <span class="st">'sadness'</span>, <span class="st">'feelings'</span>, <span class="st">'danceability'</span>,<span class="st">'loudness'</span>, <span class="st">'acousticness'</span>, <span class="st">'instrumentalness'</span>, <span class="st">'valence'</span>, <span class="st">'energy'</span>]      </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>subset_df <span class="op">=</span> df[cols]</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>average_by_genre <span class="op">=</span> subset_df.groupby(<span class="st">'genre'</span>).mean()</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>subset_avg <span class="op">=</span> average_by_genre[[<span class="st">'sadness'</span>, <span class="st">'energy'</span>]]</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>subset_avg</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sadness</th>
<th data-quarto-table-cell-role="th">energy</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">genre</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">blues</td>
<td>0.113511</td>
<td>0.581534</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">country</td>
<td>0.165922</td>
<td>0.466350</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">hip hop</td>
<td>0.036589</td>
<td>0.703236</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">jazz</td>
<td>0.124067</td>
<td>0.463430</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">pop</td>
<td>0.142083</td>
<td>0.601097</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">reggae</td>
<td>0.078312</td>
<td>0.589931</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">rock</td>
<td>0.133539</td>
<td>0.700954</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>Country music ended up having the highest average “sadness” classification, while hip-hohp had the highest average energy value, but came in very close to rock.</p>
</section>
<section id="are-acousticness-and-instrumentalness-similar-features-can-you-find-any-patterns-in-when-they-disagree" class="level4">
<h4 class="anchored" data-anchor-id="are-acousticness-and-instrumentalness-similar-features-can-you-find-any-patterns-in-when-they-disagree">3. Are acousticness and instrumentalness similar features? Can you find any patterns in when they disagree?</h4>
<p>For this question I focused on country and jazz specifically after finding they were the most common in these two genres.</p>
<div id="cell-67" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># focusing only on country and jazz</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>subset_df <span class="op">=</span> df[df[<span class="st">'genre'</span>].isin([<span class="st">'country'</span>, <span class="st">'jazz'</span>])]</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of "acousticness" against "instrumentalness" for country and jazz genres</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> genre <span class="kw">in</span> [<span class="st">'country'</span>, <span class="st">'jazz'</span>]:</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    genre_df <span class="op">=</span> subset_df[subset_df[<span class="st">'genre'</span>] <span class="op">==</span> genre]</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    plt.scatter(genre_df[<span class="st">'acousticness'</span>], genre_df[<span class="st">'instrumentalness'</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span>genre)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Acousticness'</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Instrumentalness'</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Relationship between Acousticness and Instrumentalness for Country and Jazz Genres'</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>plt.legend(bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="dv">1</span>), loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="deepmusic_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This graph didn’t show any immeadiately clear pattens, so I wanted to look more specifically at what genres appeared at the extremes (high acoustic and low instumental and vice versa).</p>
<div id="cell-69" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># subsetting data to focus on engineered features</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">'genre'</span>, <span class="st">'dating'</span>, <span class="st">'violence'</span>, <span class="st">'world/life'</span>, <span class="st">'night/time'</span>,<span class="st">'shake the audience'</span>,<span class="st">'family/gospel'</span>, <span class="st">'romantic'</span>, <span class="st">'communication'</span>,<span class="st">'obscene'</span>, <span class="st">'music'</span>, <span class="st">'movement/places'</span>, <span class="st">'light/visual perceptions'</span>,<span class="st">'family/spiritual'</span>, <span class="st">'like/girls'</span>, <span class="st">'sadness'</span>, <span class="st">'feelings'</span>, <span class="st">'danceability'</span>,<span class="st">'loudness'</span>, <span class="st">'acousticness'</span>, <span class="st">'instrumentalness'</span>, <span class="st">'valence'</span>, <span class="st">'energy'</span>]      </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>subset_df <span class="op">=</span> df[cols]</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define thresholds for high and low instrumentalness and acousticness</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>high_instrumental_threshold <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>low_instrumental_threshold <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>high_acoustic_threshold <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>low_acoustic_threshold <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># new subsets containing the high inst. and low acoustic songs and vice versa</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>high_instr_low_acoustic <span class="op">=</span> subset_df[(subset_df[<span class="st">'instrumentalness'</span>] <span class="op">&gt;</span> high_instrumental_threshold) <span class="op">&amp;</span> (subset_df[<span class="st">'acousticness'</span>] <span class="op">&lt;</span> low_acoustic_threshold)]</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>high_acoustic_low_instr <span class="op">=</span> subset_df[(subset_df[<span class="st">'acousticness'</span>] <span class="op">&gt;</span> high_acoustic_threshold) <span class="op">&amp;</span> (subset_df[<span class="st">'instrumentalness'</span>] <span class="op">&lt;</span> low_instrumental_threshold)]</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co"># find most frequent genre in each subset</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>genre_counts <span class="op">=</span> high_instr_low_acoustic[<span class="st">'genre'</span>].value_counts()</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>most_frequent_genre <span class="op">=</span> genre_counts.idxmax()</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Most frequent appearing genre within low acoustic, high instrumental:"</span>, most_frequent_genre)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>genre_counts <span class="op">=</span> high_acoustic_low_instr[<span class="st">'genre'</span>].value_counts()</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>most_frequent_genre <span class="op">=</span> genre_counts.idxmax()</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Most frequent appearing genre within high acoustic, low instrumental:"</span>, most_frequent_genre)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Most frequent appearing genre within low acoustic, high instrumental: jazz
Most frequent appearing genre within high acoustic, low instrumental: country</code></pre>
</div>
</div>
<p>This finding made sense to me, if Spotify used instumentalness to measure the presence of instruments compared to voice, and and acoustic to measure the presence of voice with fewer instuments.</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>In implementing this music genre classification task, I gained several insights through the process of building and evaluating the three neural network models. While the accuracy results were not extraordinary, with all three models scoring in the 25-30% range, they did exceed the baseline rate of 24% for randomly guessing among the 7 genres. This suggests that the models were able to extract and utilize meaningful patterns from the lyrics and engineered features, even if their predictive performance has room for improvement. One surprising finding was that combining both the text lyrics and numeric engineered features in the third model did not lead to a significant boost over the individual models. This could potentially be addressed by more advanced architectures for the combined network. Visualizing the learned word embeddings from the lyrics model revealed some unexpected clusterings, like outliers in nicknames. Overall, while beating the baseline, the relatively low accuracies showed that perfect classification remains a challenge requiring more sophisticated techniques or richer data sources. Throughout the process of implementing these models, I learned a lot about the uses of the individual layers of neural networks and the differing tasks for which they are optimal.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>